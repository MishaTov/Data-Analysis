{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c284616a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaForTokenClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFXLMRobertaForTokenClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaForTokenClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFXLMRobertaForTokenClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaForTokenClassification for predictions without further training.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Віталій', '▁Володимирович', '▁Кличко', '▁Володимир']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFXLMRobertaForTokenClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFXLMRobertaForTokenClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaForTokenClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFXLMRobertaForTokenClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaForTokenClassification for predictions without further training.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Київ', '▁України', '▁', 'Дніпро', '▁України']\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, TFAutoModelForTokenClassification\n",
    "\n",
    "def get_names(text):\n",
    "    tokenizer = AutoTokenizer.from_pretrained('ukr-models/uk-ner')\n",
    "    model = TFAutoModelForTokenClassification.from_pretrained('ukr-models/uk-ner')\n",
    "    ner = pipeline('ner', model=model, tokenizer=tokenizer)\n",
    "    entities = [word['word'] for word in ner(text)]\n",
    "    for ind, entity in enumerate(entities):\n",
    "        if entity[0].islower():\n",
    "            entities[ind-1] += entity\n",
    "            del entities[ind]\n",
    "    return entities\n",
    "\n",
    "\n",
    "text1 = \"Віталій Володимирович Кличко є багаторазовим чемпіоном світу з боксу у важкій вазі, так само як і Володимир - його брат\"\n",
    "text2 = \"Київ - столиця та найбільше місто України, у той час як Дніпро - найбільша річка України\"\n",
    "\n",
    "print(get_names(text1))\n",
    "print(get_names(text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9495afb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
